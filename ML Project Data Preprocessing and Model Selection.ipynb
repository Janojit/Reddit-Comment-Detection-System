{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f76665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173ebb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('proj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f5241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&gt; i must study politics and war, that our sons...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i was literally told as a child \"i want you ki...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>how did this even happen? \\n\\nmy grandmother u...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>bootstraps, ignore the house i bought for $10,...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>it's been a strange realization to slowly unde...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293519</th>\n",
       "      <td>293519</td>\n",
       "      <td>i'm a bills fan. spent my childhood rooting fo...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293520</th>\n",
       "      <td>293520</td>\n",
       "      <td>he ones told his mother he can fly, he called ...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293521</th>\n",
       "      <td>293521</td>\n",
       "      <td>that playoff luck from last year reverses itse...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293522</th>\n",
       "      <td>293522</td>\n",
       "      <td>with lamar this would be the game i’d most loo...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293523</th>\n",
       "      <td>293523</td>\n",
       "      <td>i’m be had allen on my ff team three years in ...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293524 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                            comment   label\n",
       "0                0  > i must study politics and war, that our sons...  normal\n",
       "1                1  i was literally told as a child \"i want you ki...  normal\n",
       "2                2  how did this even happen? \\n\\nmy grandmother u...  normal\n",
       "3                3  bootstraps, ignore the house i bought for $10,...  normal\n",
       "4                4  it's been a strange realization to slowly unde...  normal\n",
       "...            ...                                                ...     ...\n",
       "293519      293519  i'm a bills fan. spent my childhood rooting fo...  normal\n",
       "293520      293520  he ones told his mother he can fly, he called ...  normal\n",
       "293521      293521  that playoff luck from last year reverses itse...  normal\n",
       "293522      293522  with lamar this would be the game i’d most loo...  normal\n",
       "293523      293523  i’m be had allen on my ff team three years in ...  normal\n",
       "\n",
       "[293524 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a197af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f76d06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt; i must study politics and war, that our sons...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i was literally told as a child \"i want you ki...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how did this even happen? \\n\\nmy grandmother u...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bootstraps, ignore the house i bought for $10,...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's been a strange realization to slowly unde...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293519</th>\n",
       "      <td>i'm a bills fan. spent my childhood rooting fo...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293520</th>\n",
       "      <td>he ones told his mother he can fly, he called ...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293521</th>\n",
       "      <td>that playoff luck from last year reverses itse...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293522</th>\n",
       "      <td>with lamar this would be the game i’d most loo...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293523</th>\n",
       "      <td>i’m be had allen on my ff team three years in ...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293524 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment   label\n",
       "0       > i must study politics and war, that our sons...  normal\n",
       "1       i was literally told as a child \"i want you ki...  normal\n",
       "2       how did this even happen? \\n\\nmy grandmother u...  normal\n",
       "3       bootstraps, ignore the house i bought for $10,...  normal\n",
       "4       it's been a strange realization to slowly unde...  normal\n",
       "...                                                   ...     ...\n",
       "293519  i'm a bills fan. spent my childhood rooting fo...  normal\n",
       "293520  he ones told his mother he can fly, he called ...  normal\n",
       "293521  that playoff luck from last year reverses itse...  normal\n",
       "293522  with lamar this would be the game i’d most loo...  normal\n",
       "293523  i’m be had allen on my ff team three years in ...  normal\n",
       "\n",
       "[293524 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bba75",
   "metadata": {},
   "source": [
    "### Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "377ce568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment    5\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d138ac29",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- There are 5 Null values in the Dataset which we need to drop or fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de43b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316b437",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- It is better to drop those values as they are not having any significance effect on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb17de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal       286624\n",
       "provoking      6308\n",
       "racist          587\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fca6f5f",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- As per the data we scraped, we found there are more than 2.8 lakh normal comments whereas provoking comments are about 6.3K and Racist comments are about 0.5K. From which we can infer that most of the Reddit users are not Racist and Provoking or Reddit's Policy for This kind of Comments are very strict.\n",
    "- As the Data is imbalanced for classification, so we need to apply some kind of balancing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b201b495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt; i must study politics and war, that our sons...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i was literally told as a child \"i want you ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how did this even happen? \\n\\nmy grandmother u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bootstraps, ignore the house i bought for $10,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's been a strange realization to slowly unde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293519</th>\n",
       "      <td>i'm a bills fan. spent my childhood rooting fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293520</th>\n",
       "      <td>he ones told his mother he can fly, he called ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293521</th>\n",
       "      <td>that playoff luck from last year reverses itse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293522</th>\n",
       "      <td>with lamar this would be the game i’d most loo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293523</th>\n",
       "      <td>i’m be had allen on my ff team three years in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293519 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  label\n",
       "0       > i must study politics and war, that our sons...      0\n",
       "1       i was literally told as a child \"i want you ki...      0\n",
       "2       how did this even happen? \\n\\nmy grandmother u...      0\n",
       "3       bootstraps, ignore the house i bought for $10,...      0\n",
       "4       it's been a strange realization to slowly unde...      0\n",
       "...                                                   ...    ...\n",
       "293519  i'm a bills fan. spent my childhood rooting fo...      0\n",
       "293520  he ones told his mother he can fly, he called ...      0\n",
       "293521  that playoff luck from last year reverses itse...      0\n",
       "293522  with lamar this would be the game i’d most loo...      0\n",
       "293523  i’m be had allen on my ff team three years in ...      0\n",
       "\n",
       "[293519 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc835552",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- I have label encoded the labels as string values can't be given to a model\n",
    "- normal has been mapped to 0, provoking has been mapped to 1 and racist has been mapped to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20798d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa7a537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71149</th>\n",
       "      <td>gentlemen... behold!!! *beep beep beep* .....c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96137</th>\n",
       "      <td>i can't even imagine infecting a complete stra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235479</th>\n",
       "      <td>losing my job in solidarity with bob sarver is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192289</th>\n",
       "      <td>sim! no meio da confusão!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119142</th>\n",
       "      <td>lol thor isn't human got to be a new argument.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244035</th>\n",
       "      <td>fuck, now i can’t go</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143677</th>\n",
       "      <td>what a piece of shit lol.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63918</th>\n",
       "      <td>i just commented this elsewhere but as a daugh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50626</th>\n",
       "      <td>i feel like this is exactly the argument they ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>here’s a start on that initiative!\\n\\nreducing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  label\n",
       "71149   gentlemen... behold!!! *beep beep beep* .....c...      0\n",
       "96137   i can't even imagine infecting a complete stra...      0\n",
       "235479  losing my job in solidarity with bob sarver is...      0\n",
       "192289                          sim! no meio da confusão!      0\n",
       "119142     lol thor isn't human got to be a new argument.      0\n",
       "...                                                   ...    ...\n",
       "244035                               fuck, now i can’t go      0\n",
       "143677                          what a piece of shit lol.      0\n",
       "63918   i just commented this elsewhere but as a daugh...      0\n",
       "50626   i feel like this is exactly the argument they ...      0\n",
       "48849   here’s a start on that initiative!\\n\\nreducing...      0\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc6c0ee",
   "metadata": {},
   "source": [
    "**Explaination**\n",
    "- As the Scraped data was so huge so it's hard to fit models into it as our local system isn't that much efficient so. I have taken a sample of 20K out of it and going to fit those into models.\n",
    "- If we take all 2.9 Lakh data points then obiviously the accuracy will be much higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a3e7f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:852)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed\n",
      "[nltk_data]     (_ssl.c:852)>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tokenize the text in the 'text' column\n",
    "df['tokens'] = df['comment'].apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "# Load the stop words\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Remove stop words from the 'tokens' column\n",
    "df['cleaned_comment'] = df['tokens'].apply(lambda x: \" \".join(token.lower() for token in x if token.lower() not in stop_words))\n",
    "\n",
    "# Drop the 'tokens' column if it's no longer needed\n",
    "df = df.drop(columns='tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2405498e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71149</th>\n",
       "      <td>gentlemen... behold!!! *beep beep beep* .....c...</td>\n",
       "      <td>0</td>\n",
       "      <td>gentlemen ... behold ! ! ! * beep beep beep * ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96137</th>\n",
       "      <td>i can't even imagine infecting a complete stra...</td>\n",
       "      <td>0</td>\n",
       "      <td>ca n't even imagine infecting complete strange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235479</th>\n",
       "      <td>losing my job in solidarity with bob sarver is...</td>\n",
       "      <td>0</td>\n",
       "      <td>losing job solidarity bob sarver something wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192289</th>\n",
       "      <td>sim! no meio da confusão!</td>\n",
       "      <td>0</td>\n",
       "      <td>sim ! meio da confusão !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119142</th>\n",
       "      <td>lol thor isn't human got to be a new argument.</td>\n",
       "      <td>0</td>\n",
       "      <td>lol thor n't human got new argument .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244035</th>\n",
       "      <td>fuck, now i can’t go</td>\n",
       "      <td>0</td>\n",
       "      <td>fuck , ’ go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143677</th>\n",
       "      <td>what a piece of shit lol.</td>\n",
       "      <td>0</td>\n",
       "      <td>piece shit lol .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63918</th>\n",
       "      <td>i just commented this elsewhere but as a daugh...</td>\n",
       "      <td>0</td>\n",
       "      <td>commented elsewhere daughter conservatives pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50626</th>\n",
       "      <td>i feel like this is exactly the argument they ...</td>\n",
       "      <td>0</td>\n",
       "      <td>feel like exactly argument would make steer ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48849</th>\n",
       "      <td>here’s a start on that initiative!\\n\\nreducing...</td>\n",
       "      <td>0</td>\n",
       "      <td>’ start initiative ! reducing stress 101 - unr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  label  \\\n",
       "71149   gentlemen... behold!!! *beep beep beep* .....c...      0   \n",
       "96137   i can't even imagine infecting a complete stra...      0   \n",
       "235479  losing my job in solidarity with bob sarver is...      0   \n",
       "192289                          sim! no meio da confusão!      0   \n",
       "119142     lol thor isn't human got to be a new argument.      0   \n",
       "...                                                   ...    ...   \n",
       "244035                               fuck, now i can’t go      0   \n",
       "143677                          what a piece of shit lol.      0   \n",
       "63918   i just commented this elsewhere but as a daugh...      0   \n",
       "50626   i feel like this is exactly the argument they ...      0   \n",
       "48849   here’s a start on that initiative!\\n\\nreducing...      0   \n",
       "\n",
       "                                          cleaned_comment  \n",
       "71149   gentlemen ... behold ! ! ! * beep beep beep * ...  \n",
       "96137   ca n't even imagine infecting complete strange...  \n",
       "235479  losing job solidarity bob sarver something wan...  \n",
       "192289                           sim ! meio da confusão !  \n",
       "119142              lol thor n't human got new argument .  \n",
       "...                                                   ...  \n",
       "244035                                        fuck , ’ go  \n",
       "143677                                   piece shit lol .  \n",
       "63918   commented elsewhere daughter conservatives pro...  \n",
       "50626   feel like exactly argument would make steer ar...  \n",
       "48849   ’ start initiative ! reducing stress 101 - unr...  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acf3bf6",
   "metadata": {},
   "source": [
    "**Explaination**\n",
    "- Using \"nltk\" library we are ignoring the common words which are not significant for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "004249e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19534\n",
       "1      437\n",
       "2       29\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06e7f7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['cleaned_comment'], df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b530c",
   "metadata": {},
   "source": [
    "**Explaination**\n",
    "- Selecting X(Feature) and y(Target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b09e213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gentlemen ... behold ! ! ! * beep beep beep * ..... corn ! ! !',\n",
       "       \"ca n't even imagine infecting complete stranger , let alone kids . really sorry happened parents cultists said , little hope right thing going forward . 'm sure many others infected , besides , . seen nation makes afraid future , esp . light pandemics coming pike . polio re-emerged uk monkeypox may `` pox '' horizon .\",\n",
       "       'losing job solidarity bob sarver something want lol', ...,\n",
       "       'commented elsewhere daughter conservatives promise ’ care woman regardless relation',\n",
       "       \"feel like exactly argument would make steer argument away something . 're still much higher countries think worse united states , think 's clear something needs done getting `` data countries might accurate might bad '' constructive .\",\n",
       "       '’ start initiative ! reducing stress 101 - unreasonable deadlines ( _really_ need ? )'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08eac840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Convert X to a sparse matrix of token counts\n",
    "cv = CountVectorizer()\n",
    "X_count = cv.fit_transform(X)\n",
    "\n",
    "# Convert X_count to a CSR matrix\n",
    "X_count = csr_matrix(X_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2050ef26",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- To convert the text dataset into a proper dataframe I have used Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e257da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: \n",
      " 0    19534\n",
      "1      437\n",
      "2       29\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Original dataset shape:\",\"\\n\", pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02be886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: \n",
      " 2    19534\n",
      "1    19534\n",
      "0    19534\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X_count, y)\n",
    "\n",
    "print(\"Resampled dataset shape:\",'\\n',pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653447a3",
   "metadata": {},
   "source": [
    "**Explaination**\n",
    "- As the Sampled data was also imbalanced so I have applied SMOTE technique to balanced the dataset\n",
    "- SMOTE is a statistical technique for increasing the number of cases in your dataset in a balanced way. The component works by generating new instances from existing minority cases that you supply as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8e7736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4690b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNB(test_size, random_state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = test_size, random_state = random_state)\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "    return acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e901b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGR(test_size, random_state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = test_size, random_state = random_state)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "    return acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1463544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTC(test_size, random_state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = test_size, random_state = random_state)\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "    return acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9204ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFC(test_size, random_state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = test_size, random_state = random_state)\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    model = model\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "    return acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5246770",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe = pd.DataFrame(columns = ['Model', 'Test Size', 'Random State', 'Accuracy','AUC'])\n",
    "random_states = [10,20,30,40,42,50,60]\n",
    "test_sizes = [0.20,0.25,0.30]\n",
    "\n",
    "for r_s in random_states:\n",
    "    for ts in test_sizes:\n",
    "        acc, auc= MNB(ts, r_s)\n",
    "        result = {}\n",
    "        result['Model'] = 'MultinomialNB'\n",
    "        result['Test Size'] = ts\n",
    "        result['Random State'] = r_s\n",
    "        result['Accuracy'] = acc\n",
    "        result['AUC'] = auc\n",
    "        results_dataframe = results_dataframe.append(result, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b614b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_s in random_states:\n",
    "    for ts in test_sizes:\n",
    "        acc, auc= LGR(ts, r_s)\n",
    "        result = {}\n",
    "        result['Model'] = 'LogisticRegression'\n",
    "        result['Test Size'] = ts\n",
    "        result['Random State'] = r_s\n",
    "        result['Accuracy'] = acc\n",
    "        result['AUC'] = auc\n",
    "        results_dataframe = results_dataframe.append(result, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26cfb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_s in random_states:\n",
    "    for ts in test_sizes:\n",
    "        acc, auc= DTC(ts, r_s)\n",
    "        result = {}\n",
    "        result['Model'] = 'DecisionTreeClassifier'\n",
    "        result['Test Size'] = ts\n",
    "        result['Random State'] = r_s\n",
    "        result['Accuracy'] = acc\n",
    "        result['AUC'] = auc\n",
    "        results_dataframe = results_dataframe.append(result, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a82f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_s in random_states:\n",
    "    for ts in test_sizes:\n",
    "        acc, auc= RFC(ts, r_s)\n",
    "        result = {}\n",
    "        result['Model'] = 'RandomForestClassifier'\n",
    "        result['Test Size'] = ts\n",
    "        result['Random State'] = r_s\n",
    "        result['Accuracy'] = acc\n",
    "        result['AUC'] = auc\n",
    "        results_dataframe = results_dataframe.append(result, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataframe.to_csv(\"preddd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274bfd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7fa0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = results_dataframe, y = 'Accuracy', x = 'Test Size',hue = 'Model', kind = 'box')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490c45d7",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- As per the Catplot b/w Accuracy and Test Size Random Forest has the highest Accuracy with the test size 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = results_dataframe, y = 'AUC', x = 'Test Size',hue = 'Model', kind = 'box')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62024774",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- As per the Catplot b/w AUC and Test Size Random Forest has the highest AUC with test size 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = results_dataframe, y = 'Accuracy', x = 'Random State',hue = 'Model', kind = 'box')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f9f6a8",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- As per the Catplot b/w Accuracy and Random State Random Forest has the highest Accuracy with Random Size 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435eb172",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data = results_dataframe, y = 'AUC', x = 'Random State',hue = 'Model', kind = 'box')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f405fbc0",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "- As per the Catplot b/w AUC and Random State Random Forest has almost the highest AUC with Random Size 20, 30, 40 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096084b7",
   "metadata": {},
   "source": [
    "**Overall Observation:**\n",
    "- Random Forest is the best model for this case with Test Size 0.2 and Random State 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1316d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC(0.2,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size = 0.2, random_state = 40)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158643d",
   "metadata": {},
   "source": [
    "### Exporting Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a157222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f271b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open(\"model.pickle\", 'wb'))\n",
    "pickle.dump(le, open(\"le.pickle\", 'wb'))\n",
    "pickle.dump(cv, open(\"cv.pickle\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
